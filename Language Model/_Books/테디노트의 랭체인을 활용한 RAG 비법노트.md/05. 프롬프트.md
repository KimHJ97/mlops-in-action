# 프롬프트

프롬프트 단계는 검색기에서 검색된 문서들을 바탕으로 언어 모델이 사용할 질문이나 명령을 생성하는 과정이다.

 - 문맥(Context) 설정: 프롬프트는 언어 모델이 특정 문맥에서 작동하도록 설정하는 역할을 한다. 이를 통해 모델은 제공된 정보를 바탕으로 보다 정확하고 관련성 높은 답변을 생성할 수 있다.
 - 정보 통합: 여러 문서에서 검색된 정보는 서로 다른 관점이나 내용을 포함할 수 있다. 프롬프트 단계에서 이러한 정보를 통합하고, 모델이 이를 효율적으로 활용할 수 있는 형식으로 조정한다.
 - 응답 품질 향상: 질문에 대한 모델의 응답 품질은 프롬프트의 구성에 크게 의존한다. 잘 구성된 프롬프트는 모델이 보다 정확하고 유용한 정보를 제공하게 돕는다.
 - __프롬프트 구조__
    - 지시사항
    - 질문(사용자 입력 질문)
    - 문맥(검색된 정보)
```
당신은 질문-답변(Question-Answer) Task 를 수행한는 AI 어시스턴트 입니다.
검색된 문맥(context)를 사용하여 질문(question)에 답하세요. 
만약, 문맥(context) 으로부터 답을 찾을 수 없다면 '모른다' 고 말하세요. 
한국어로 대답하세요.

#Question: 
{이곳에 사용자가 입력한 질문이 삽입됩니다}

#Context: 
{이곳에 검색된 정보가 삽입됩니다}
```
<br/>

## 1. 프롬프트 템플릿 만들기

 - `from_template() 메소드를 사용하여 PromptTemplate 객체 생성`
```python
from langchain_core.prompts import PromptTemplate

template = "{country}의 수도는 어디인가요?"
prompt = PromptTemplate.from_template(template)

# Chain 생성
chain = prompt | llm

chain.invoke("대한민국")
```
<br/>

 - `PromptTemplate 객체 생성과 동시에 prompt 생성`
```python
template = "{country}의 수도는 어디인가요?"
prompt = PromptTemplate(
    template=template,
    input_variables=["country"],
)
prompt.format(country="대한민국")
```
<br/>

 - `일부 변수 확정 짓기(partial_variables)`
    - 두 개 이상의 변수를 처리하는 경우 partial_variables를 이용하여 일부 변수를 확정지을 수 있다.
```python
template = "{country1}과 {country2}의 수도는 각각 어디인가요?"
prompt = PromptTemplate(
    template=template,
    input_variables=["country1"],
    partial_variables={
        "country2": "미국"  # dictionary 형태로 partial_variables를 전달
    },
)

prompt.format(country1="대한민국") # '대한민국과 미국의 수도는 각각 어디인가요?'

# partial() 메서드를 사용하면 템플릿의 일부 변수를 미리 채워 둘 수 있다.
prompt_partial = prompt.partial(country2="캐나다")
prompt_partial.format(country1="대한민국") # '대한민국과 캐나다의 수도는 각각 어디인가요?'

# partial()로 설정된 값도 새로운 값으로 대체될 수 있다. (체인에서 invoke() 메서드로 설정시)
chain.invoke({"country1": "대한민국", "country2": "호주"}).content # '대한민국의 수도는 서울이고 호주의 수도는 캔버라입니다.'
```
<br/>


 - `partial_varialbes(함수 사용)`
    - partial을 사용하는 일반적인 용도는 함수를 부분적으로 사용하는 것이다.
```python
from datetime import datetime

# 오늘 날짜를 출력
datetime.now().strftime("%B %d")

# 날짜를 반환하는 함수 정의
def get_today():
    return datetime.now().strftime("%B %d")

prompt = PromptTemplate(
    template="오늘의 날짜는 {today} 입니다. 오늘이 생일인 유명인 {n}명을 나열해 주세요. 생년월일을 표기해주세요.",
    input_variables=["n"],
    partial_variables={
        "today": get_today  # dictionary 형태로 partial_variables를 전달
    },
)
prompt.format(n=3)
chain = prompt | llm


print(chain.invoke(3).content)
print(chain.invoke({"today": "Jan 02", "n": 3}).content)
```
<br/>

### 1-1. 파일로부터 템플릿 읽어오기

#### 짧은 템플릿

 - `prompts/fruit_color.yaml`
```yml
_type: "prompt"
template: "{fruit}의 색깔이 뭐야?"
input_variables: ["fruit"]
```
<br/>

```python
from langchain_core.prompts import load_prompt

prompt = load_prompt("prompts/fruit_color.yaml", encoding="utf-8")
prompt.format(fruit="사과")
```

#### 긴 템플릿

 - `prompts/capital.yaml`
```yml
_type: "prompt"
template: "{|
  {country}의 수도에 대해서 알려주세요.
  수도의 특징을 다음의 양식에 맞게 정리해 주세요.
  300자 내외로 작성해 주세요.
  한글로 작성해 주세요.
  ---
  [양식]
  1. 면적
  2. 인구
  3. 역사적 장소
  4. 특산품
     #Answer:
input_variables: ["country"]
```
<br/>

```python
prompt2 = load_prompt("prompts/capital.yaml")
print(prompt2.format(country="대한민국"))
```
<br/>

### 1-2. ChatPromptTemplate

ChatPromptTemplate 은 대화목록을 프롬프트로 주입하고자 할 때 활용할 수 있습니다. 메시지는 튜플(tuple) 형식으로 구성하며, (role, message) 로 구성하여 리스트로 생성할 수 있습니다.
 - "system": 시스템 설정 메시지 입니다. 주로 전역설정과 관련된 프롬프트입니다.
 - "human" : 사용자 입력 메시지 입니다.
 - "ai": AI 의 답변 메시지입니다.

```python
from langchain_core.prompts import ChatPromptTemplate

chat_prompt = ChatPromptTemplate.from_template("{country}의 수도는 어디인가요?")
chat_prompt.format(country="대한민국")
# 'Human: 대한민국의 수도는 어디인가요?'
```

 - ``
```python
from langchain_core.prompts import ChatPromptTemplate

chat_template = ChatPromptTemplate.from_messages(
    [
        # role, message
        ("system", "당신은 친절한 AI 어시스턴트입니다. 당신의 이름은 {name} 입니다."),
        ("human", "반가워요!"),
        ("ai", "안녕하세요! 무엇을 도와드릴까요?"),
        ("human", "{user_input}"),
    ]
)

# 챗 message 를 생성합니다.
messages = chat_template.format_messages(
    name="로그", user_input="당신의 이름은 무엇입니까?"
)
messages
# [SystemMessage(content='당신은 친절한 AI 어시스턴트입니다. 당신의 이름은 테디 입니다.'), HumanMessage(content='반가워요!'), AIMessage(content='안녕하세요! 무엇을 도와드릴까요?'), HumanMessage(content='당신의 이름은 무엇입니까?')]

# LLM 요청
llm.invoke(messages).content


# 체인을 생성하여 요청
chain = chat_template | llm
chain.invoke({"name": "Teddy", "user_input": "당신의 이름은 무엇입니까?"}).content
```
<br/>

### 1-3. MessagePlaceholder

MessagesPlaceholder는 대화에서 아직 확정된 메시지는 아니지만 나중에 채워질 메시지를 채우기 위해 임시로 확보한 자리를 말한다.  

챗봇을 만들 때 대화를 주고받으며 그 내용을 기록하고자 할 때 MeessagesPlaceholder가 자주 사용되낟. 대화는 진행 중에 계속 쌓이지만, 모든 대화 내용이 확정되기 전이므로 MessagesPlaceholder에 저장해 두었다가 나중에 대화 기록을 분석하거나 다른 질문에 활용할 수 있다.

```python
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

chat_prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            "당신은 요약 전문 AI 어시스턴트입니다. 당신의 임무는 주요 키워드로 대화를 요약하는 것입니다.",
        ),
        MessagesPlaceholder(variable_name="conversation"),
        ("human", "지금까지의 대화를 {word_count} 단어로 요약합니다."),
    ]
)

formatted_chat_prompt = chat_prompt.format(
    word_count=5,
    conversation=[
        ("human", "안녕하세요! 저는 오늘 새로 입사한 로그 입니다. 만나서 반갑습니다."),
        ("ai", "반가워요! 앞으로 잘 부탁 드립니다."),
    ],
)

print(formatted_chat_prompt)
# System: 당신은 요약 전문 AI 어시스턴트입니다. 당신의 임무는 주요 키워드로 대화를 요약하는 것입니다.
# Human: 안녕하세요! 저는 오늘 새로 입사한 로그 입니다. 만나서 반갑습니다.
# AI: 반가워요! 앞으로 잘 부탁 드립니다.
# Human: 지금까지의 대화를 5 단어로 요약합니다.




# chain 생성 후 실행
chain = chat_prompt | llm | StrOutputParser()
chain.invoke(
    {
        "word_count": 5,
        "conversation": [
            (
                "human",
                "안녕하세요! 저는 오늘 새로 입사한 로그 입니다. 만나서 반갑습니다.",
            ),
            ("ai", "반가워요! 앞으로 잘 부탁 드립니다."),
        ],
    }
)
```
<br/>

## 2. 퓨샷 프롬프트

### 2-1. 퓨샷 프롬프트란?

 - 제로샷(Zero-shot): 예시 없이 “지시만” 주고 답을 받는 방식
 - 원샷(One-shot): 예시 1개(입력→모범 출력)를 같이 줘서 모델이 출력 형식/논리를 학습하도록 유도
 - 퓨샷(Few-shot): 두 개 이상의 예시를 제공하여 문체, 단계, 포맷, 추론 흐름을 더 안정적으로 따라 하게 함

### 2-2. 퓨샷 프롬프트 예시

```python
from langchain.prompts import FewShotPromptTemplate, PromptTemplate

# 1. 각 예시를 어떻게 포맷팅할지 정의
example_prompt = PromptTemplate(
    input_variables=["question", "answer"],
    template="Q: {question}\nA: {answer}"
)

# 2. 예시 데이터 정의
examples = [
    {"question": "What is 2+2?", "answer": "4"},
    {"question": "What is the capital of France?", "answer": "Paris"},
]

# 3. FewShotPromptTemplate 정의
few_shot_prompt = FewShotPromptTemplate(
    examples=examples,             # 위에서 정의한 예시 리스트
    example_prompt=example_prompt, # 예시 포맷
    prefix="You are a helpful assistant. Answer the questions below:",
    suffix="Q: {input}\nA:",       # 실제 유저 입력이 들어갈 자리
    input_variables=["input"],     # suffix에서 사용될 변수
    example_separator="\n\n"       # 예시 간 구분자
)

# 4. 프롬프트 생성
print(few_shot_prompt.format(input="What is 3*3?"))

# 5. 사용 예시
chain = few_shot_prompt | llm | StrOutputParser()
answer = chain.invoke(
    {"input": "What is 3*3?"}
)
```

 - `출력 예시(최종 생성된 프롬프트)`
    - 프리픽스 -> 예시들(examples, example_prompt) -> 유저 입력(suffix)
```bash
You are a helpful assistant. Answer the questions below:

Q: What is 2+2?
A: 4

Q: What is the capital of France?
A: Paris

Q: What is 3*3?
A:
```
<br/>

### 2-3. Example Selector (예제 선택기)

 - FewShotPromptTemplate는 예시(Few-shot examples) 를 무조건 전부 붙여주는데, 실제로는 질문과 가장 비슷한 예시 몇 개만 선택해서 프롬프트에 넣는 게 더 효율적일 때가 많다.
 - FewShotPromptTemplate 안에 들어가는 examples를 동적으로 선택해 주는 컴포넌트
 - 사용자 입력과 가장 유사한 예시 N개만 가져오기, 랜덤 샘플링, 규칙 기반 필터링 등이 가능
 - __SemanticSimilarityExampleSelector__: 벡터 DB(예: FAISS, Chroma)에 예시를 임베딩해서 저장. 유저 입력과 의미적으로 가까운 예시만 뽑아서 반환.
 - __LengthBasedExampleSelector__: 프롬프트 길이를 초과하지 않도록 예시 개수를 동적으로 조절.
 - __MaxMarginalRelevanceExampleSelector__: 중복이 적고 다양성이 높은 예시를 선택 (MMR 알고리즘).

```python
from langchain.prompts import FewShotPromptTemplate, PromptTemplate
from langchain.prompts.example_selector import SemanticSimilarityExampleSelector
from langchain_openai import OpenAIEmbeddings
from langchain.vectorstores import FAISS

# 1. 예시 데이터
examples = [
    {"question": "What is 2+2?", "answer": "4"},
    {"question": "What is the capital of France?", "answer": "Paris"},
    {"question": "What is the capital of Germany?", "answer": "Berlin"},
    {"question": "What is 3*3?", "answer": "9"},
]

# 2. 예시 포맷
example_prompt = PromptTemplate(
    input_variables=["question", "answer"],
    template="Q: {question}\nA: {answer}"
)

# 3. SemanticSimilarityExampleSelector 정의
example_selector = SemanticSimilarityExampleSelector.from_examples(
    examples,              # 선택 가능한 예시 목록
    OpenAIEmbeddings(),    # 임베딩 모델
    FAISS,                 # VectorStore
    k=2                    # 입력과 가장 유사한 2개 예시 선택
)

# 4. FewShotPromptTemplate 정의
few_shot_prompt = FewShotPromptTemplate(
    example_selector=example_selector,
    example_prompt=example_prompt,
    prefix="You are a helpful assistant. Answer the questions below:",
    suffix="Q: {input}\nA:",
    input_variables=["input"],
    example_separator="\n\n"
)

# 5. 실행
print(few_shot_prompt.format(input="What is 5+5?"))
```
<br/>

 - `출력 예시(최종 생성된 프롬프트)`
```bash
You are a helpful assistant. Answer the questions below:

Q: What is 2+2?
A: 4

Q: What is 3*3?
A: 9

Q: What is 5+5?
A:
```
<br/>

### 2-4. FewShotChatMessagePromptTemplate

FewShotChatMessagePromptTemplate는 FewShotPromptTemplate의 Chat 메시지 버전이라고 이해하면 된다. 대화형(Chat) 모델에서 few-shot 예시를 손쉽게 붙여주는 도구이다.

 - FewShotPromptTemplate: 프롬프트를 문자열로 만들어서 LLM에 전달.
 - FewShotChatMessagePromptTemplate: 예시들을 ChatMessage 형태로 변환해서 LLM에 전달.
 - __주요 구성 요소__
    - examples
        - few-shot 예시 리스트 (dict 형태).
        - 예: {"input": "Hello", "output": "Hi, how can I help you?"}
    - example_prompt
        - 예시를 ChatMessageTemplate으로 정의.
        - 즉, 시스템/유저/어시스턴트 역할을 지정할 수 있음.
    - example_separator
        - 예시 사이에 구분자 역할 (보통 생략 가능).
    - prefix / suffix
        - 프롬프트 앞뒤에 고정으로 붙는 메시지.

```python
from langchain.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate
from langchain.prompts.chat import ChatMessagePromptTemplate

# 1. 예시 데이터
examples = [
    {"input": "Hello", "output": "Hi there! How can I help you?"},
    {"input": "What is 2+2?", "output": "2+2 equals 4."},
]

# 2. 각 예시를 ChatMessage 형태로 정의
example_prompt = ChatPromptTemplate.from_messages([
    ("human", "{input}"),
    ("ai", "{output}"),
])

# 3. FewShotChatMessagePromptTemplate 정의
few_shot_prompt = FewShotChatMessagePromptTemplate(
    examples=examples,
    example_prompt=example_prompt,
    prefix=[("system", "You are a friendly chatbot.")],
    suffix=[("human", "{input}")],
    input_variables=["input"]
)

# 4. 실제 프롬프트 만들기
chat_prompt = ChatPromptTemplate.from_messages([
    few_shot_prompt  # 여기서 FewShotChatMessagePromptTemplate 삽입
])
#chat_prompt = ChatPromptTemplate.from_messages([
#    ("system", "You are a friendly chatbot.")
#    few_shot_prompt
#    ("human", "{input}")
#])

print(chat_prompt.format_messages(input="Can you tell me a joke?"))

```
<br/>

 - `출력 예시(최종 생성된 프롬프트)`
```bash
System: You are a friendly chatbot.

Human: Hello
AI: Hi there! How can I help you?

Human: What is 2+2?
AI: 2+2 equals 4.

Human: Can you tell me a joke?
```
<br/>

## 3. LangChain Hub

LangChain Hub는 프롬프트 공유 페이지로, 사용자들은 자신이 작성한 프롬프트를 업로드하거나 다른 사용자가 만든 프롬프트를 간편하게 다운로드해 활용할 수 있다.
 - LangChain Hub 주소: https://smith.langchain.com/hub

<br/>

### 3-1. 프롬프트 가져오기

```python
from langchain import hub

# 가장 최신 버전의 프롬프트 가져오기
prompt = hub.pull("rlm/rag-prompt")

# 특정 버전의 프롬프트 가져오기
prompt = hub.pull("rlm/rag-prompt:50442af1")
```

### 3-2. 플모프트 등록하기

```python
from langchain.prompts import ChatPromptTemplate
from langchain import hub

prompt = ChatPromptTemplate.from_template(
    "주어진 내용을 바탕으로 다음 문장을 요약하세요. 답변은 반드시 한글로 작성하세요\n\nCONTEXT: {context}\n\nSUMMARY:"
)

# 프롬프트를 허브에 업로드합니다.
hub.push("teddynote/simple-summary-korean", prompt)
```
