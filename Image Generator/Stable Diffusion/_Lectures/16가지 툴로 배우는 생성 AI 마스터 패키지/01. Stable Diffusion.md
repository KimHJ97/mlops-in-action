# Stable Diffusion

Stable Diffusion은 텍스트를 기반으로 이미지를 생성하는 인공지능 모델입니다. 사용자가 입력한 설명(텍스트 프롬프트)을 바탕으로 고해상도의 이미지를 생성해내는 딥러닝 기반의 텍스트-투-이미지(text-to-image) 모델입니다.

 - 개발자: Stability AI (기타 협력: Runway, CompVis, LAION 등)
 - 공개 시점: 2022년
 - 기술 기반: 딥러닝, 특히 Latent Diffusion Models (LDM) 사용
 - 주요 기능: 텍스트를 기반으로 현실감 있는 이미지 생성
 - 오픈소스: 누구나 사용할 수 있도록 소스 공개됨

## 1. Stable Diffusion 설치 및 기본 설정

 - Python 설치: https://www.python.org/downloads/release/python-3106/
 - Git SCM 설치: https://git-scm.com/downloads/win

```bash
# 적절한 디렉토리에서 git clone 진행
git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git

# 이후 다운로드한 디렉토리로 이동하여 webui.bat 파일 실행
cd stable-diffusion-webui
webui.bat
```

### 1-1. 인터페이스 기능 설명

 - Checkpoin: 이미지 생성의 기반이 되는 학습 모델
 - Prompt(긍정/부정): 생성하고자 하는 이미지 설명
 - Sampling Method(샘플링 방식): 이미지 생성 알고리즘 방식
 - Sampling Steps: 잡음 제거 알고리즘 수행 횟수
 - Batch Count: 이미지 생성 횟수
 - CFG Scale: 모델이 프롬프트를 얼마나 따르는지 결정
 - Seed: 결과값에 붙는 고유 번호

### 1-2. 기본값 설정

 - `webui-user.bat`
    - 다운로드 디렉토리내의 webui-user.bat 파일을 열어 내용을 수정한다.
    - --theme dark: 다크모드로 변경
    - --no-half-vae: Vae 모델을 16비트로 변환하지 않는다.
    - --autolaunch: WebUI 구동 시 자동으로 화면을 띄운다.
    - --medvram, lowvram: 낮은 메모리 사용시, 최적화를 진행한다. (속도가 느려짐)
    - --xfromers: 최적화 관련. 더 빠른 속도와 적은 메모리 소비
```bat
@echo off

set PYTHON=
set GIT=
set VENV_DIR=
set COMMANDLINE_ARGS= --theme dark --no-half-vae --autolaunch --xformers

call webui.bat
```

### 1-3. VAE 설정

모델을 받아 이미지를 생성해보면 약간 물먹은 듯한 흐린 이미지가 나오게 되는데, 이는 VAE 설정이 되지 않았기 때문이다.

다양한 종류의 VAE가 존재하며, 가장 많이 사용되는 VAE 하나를 사용해도 무방하다.

 - https://huggingface.co/AIARTCHAN/aichan_blend/tree/main/vae
 - 폴더/models/VAE 경로에 VAE 파일을 넣은 후 WebUI를 재실행한다.
 - WebUI > Settings > VAE > 적용

### 1-4. 익스텐션

 - WebUI > Extensions > Available
    - ko_KR Localization: 한국어 설정
    - Booru tag autocompletion prompting: 프롬프트 자동 완성
    - A디테일러: 이미지의 특정 부분에 대해서 이미지를 생성(인페인팅)

## 2. 프롬프트 기초 사용법

### 2-1. 프롬프트

프롬프트는 단어 혹은 문장으로 구성할 수 있으며, 문장보다는 단어로 사용하는 것이 추천된다. (수정 및 관리 용이)

 - 프롬프트의 단어는 ","를 이용하여 구분하고 먼저 쓰여진 단어가 더 높은 우선순위를 갖는다.
 - 사용된 단어는 괄호 기호를 통하여 가중치를 변경할 수 있다. (키워드:가중치)
    - 기본적으로 아무것도 표기하지 않으면 가중치 1
    - 1보다 크면 강조, 1보다 낮으면 덜 강조
    - 예시: (1girl:1.3) 30% 강조, (1girl:0.6) 40%만큼 덜 강조
    - 절대값이 아니라 상대값이다.

### 2-2. 네거티브 프롬프트

기본 동작 방식은 긍정 프롬프트와 동일하지만, 반대초 원치 않는 키워드를 포함하는 방식이다.

동일한 개념으로 강조 등 프롬프트 문법이 모두 적용된다.

 - 처음부터 많은 네거티브를 사용하기보다는, 이미지 생성을 먼저 진행한 뒤 거기서 덜어내는 방식으로 사용한다. 동일 시드 생성하면서 활용하는 경우가 더 많다.

### 2-3. BREAK 활용

BREAK는 토큰을 의도적으로 구분할 수 있는 문법이다.

 - BREAK로 구분하면 두 개의 덩어리를 처리하게 된다. BREAK 뒤에 키워드는 다시 최고 우선순위로 올라온다.
 - BREAK는 모두 대문자로 사용하며 앞뒤로 ","를 사용하지 않는다.
 - BREAK 문법은 일반적으로 사용하기 쉽지 않다. 강조가 더 많이 되면서 간섭이 많이 발생하게 된다.
```prompt
2girl, forest, sky
BREAK
(red_hat and white_shirt:1.3)
BREAK
(blue_hat and black_shirt:1.3)
```

### 2-4. 프롬프트 단계적 구성

프롬프트를 잘 쓴다는 것은 방향성을 제대로 제시할 수 있는 프롬프트이다. 내가 생각하는 범위에서 벗어나지 않으면서 AI가 넓은 범위로 결과를 제안할 수 있는 프롬프트를 구성하는 것이다.

이미지에 대한 범위를 굉장히 많이 나눌 수 있지만, 퀄리티 & 캐릭터 & 행동 및 감정 & 스타일 & 카메라구도 & 조명 등으로 제어하면 웬만한 형태의 이미지 타입은 전부 제어할 수 있게 된다.

 - `퀄리티(전체적인 이미지 퀄리티)`
    - AI가 이미지를 생성할 때 기본적으로 좋은 퀄리티의 이미지를 많이 참고해서 그 결과로 더 좋은 퀄리티를 내도록 하는 접근에서 사용하는 키워드
    - 프롬프트 맨 처음을 퀄리티 제어 프롬프트로 시작하는 경우가 많다.
    - Masterpice의 경우 퀄리티 제어도 되지만 실제 걸작의 의미를 담아 예술 작품이나 액자 등이 표현되는 경우가 있으니 주의가 필요하다. detail과 관련된 퀄리티 키워드는 복잡한 이미지를 잘 표현하지만, 복잡하지 않은 이미지도 복잡하게 만드는 문제가 있을 수 있다.
    - 긍정: Masterpiece, high/super/hyper/best quality, 4k, 8k, high_resolution, extremely detailed CG, intricate details, finely detailed
    - 부정: bad quality, worst quality, low quality, normal quality
 - `캐릭터(외형)`
    - 캐릭터 외형은 어떠한 키워드로 이야기하기엔 너무 범위가 넓다. 어떤 것까지 제어하는지가 중요하다. 머리부터 발끝까지 내용 중 제어하고 싶은 영역을 적는다.
    - 머리카락:  dishebeled_hair, straight_color_hair, short_hair, ponytail, showing one's forehead, pomade_hair
    - 얼굴: color_eyes, thin_color_lips, beautiful_face, beard, looking at viewer, makeup, eyeliner
    - 신체: tall, large_breasts, muscular, curvy, fat, tan
    - 의상: blouse, vest, cardigan, color_shirt, dress, jacket, blazer, robe, pants, jean, skirt, suit, bikini
    - 모자: hair_ribbon, hairband, hat, bandana, cap, circlet, crown, tiara, witch_hat, helmet
 - `행동 및 감정(표정이나 몸짓 등을 표현)`
    - 동적인 이미지를 만드려면 반드시 필요한 부분으로 그냥 감정을 넣어도 되지만 감정을 나타내는 액션 자체를 넣는 것이 조금 더 직관적으로 동작한다.
    - 감정이나 표현은 대부분 얼굴 중심으로 진행되기에 얼굴 중심의 키워드를 같이 사용하면 더 용이하며, 반대로 전신이나 배경이 많이 나오는 방식의 이미지에서는 적합하지 않다.
    - 감정의 경우 클로즈업하여 얼굴이 가깝게 나오면 잘 활용될 수 있으나, 얼굴이 작게 나오는 이미지에서는 오히려 노이즈를 일으켜 지저분하게 변경되는 경우가 발생할 수 있다.
    - 감정: Happy, surprised, distressed, sleppy, sad, angry, embarrassed, boring
    - 표현: smile, crying, tear, sobbing, chewing, closed_mouth, squiniting, glaring
 - `스타일(이미지 표현 방식)`
    - 어떤 이미지는 같은 그림이 아니라 포스터 아트, 유화 느낌을 가진다. 이런 것들 또한 프롬프트로 제어가 가능하다.
    - 보편적인 것을 다루는 모델에서는 이런 키워드가 어느정도 동작하지만 실제로 섬세하게 다루기 위해서는 해당 스타일을 전문으로 학습한 모델을 사용하고 키워드를 더하는 것이 효과적이다.
    - 스타일: Oil_painting, poster_art, film, retro, niji, cinematic, baroque, Disney-style
    - 분위기: vibrant, radiant, dreamy, hazy, glossy, multicolored, dark, ethereal
 - `카메라 구도(이미지를 바라보는 시점)`
    - AI 이미지 생성을 할 떄에는 카메라 구도에 대해서 반드시 신경쓰는 것이 좋다.
    - From_Below를 하면 아래서 바라보는 느낌, close-up을 하면 상체와 얼굴 위주로 확대하여, full_body를 하면 전신, eye focus를 하면 앞에서 얼굴을 바라보는 시점으로 이미지가 생성된다.
    - Wide_shot, full_body, upper_body, landscape, eye_focus, close-up, Dutch_Angle, From_Below, top_view
 - `조명`
    - 조명을 사용하다보면 그에 따른 퀄리티 차이가 크다는 것을 인지할 수 있다. 특히, 실사풍의 체크포인트 모델로 이미지 생성을 할 때에는 자연스러운 실사 풍에는 조명이 굉장히 중요하다.
    - Natural light, studio flash, depth of field, lensflare, best lighting, glow_red_thing, shine, cinematic light

### 2-5. 고해상도 이미지를 만드는 업스케일링

 - `해상도 512x512 (quality, girl)`
    - 여러번 이미지를 생성하면 계속해서 __얼굴 구도 위주로 이미지__ 가 만들어진다.
    - 상대적으로 좁은 공간에 디테일한 작업을 진행하기 어렵기에 확대된 근접 구도를 그리는 것이 퀄리티가 높게 나오기 때문이다.
    - 실제 몸이 나온 이미지의 경우 퀄리티가 상대적으로 떨어진다.
 - `해상도 512x512 (quality, girl, full_body)`
    - 강제로 전신이 나오는 프롬프트를 넣으면 전신이 나오긴 하지만, __그릴 수 있는 해상도 영역 자체가 낮아 얼굴 등 디테일은 뭉개진다.__
    - 작은 해상도 내에서 일부분의 디테일을 다 그리기가 어렵다.
 - `해상도 1536x512 (quality, girl)`
    - 예시로 girl이라는 프롬프트 하나인데도 2명이 그려진다.
    - 가로로 긴 영역을 혼자서 채우는 이미지보다 2인 이상으로 채워진 이미지가 많아 그런 것들을 학습했을 수 있다.
 - `해상도 1536x512 (quality, girl, close_up)`
    - 가로로 넓은 사이즈에서 클로즈업 프롬프트를 추가하여 얼굴을 생성한다.
    - 중앙에 인물의 얼굴이 나오고, 좌우 공백으로 배경을 채우는 것을 예상하지만, 얼굴이 잘리더라도 확대하여 얼굴로 화면을 가득 채우게 된다.
    - 해상도와 카메라 구도, 캐릭터는 상당한 연관 관계가 있다.
 - `해상도 1536x1536 (quality, girl)`
    - 512x512 공간보다 9배가 많아지게 되므로 생성 시간이 상당히 오래걸린다.
    - 비율과 관계없이 해상도가 크면 그 영역에 유의미한 결과를 채우기 위해 2인 이상의 인물들이 많이 나오는 편이다. 즉, 상대적인 비율과 관계없이 정말 해상도에 따른 영역 당 정보를 채워넣는 느낌이다.

#### 고해상도 보정

복잡도를 줄인 이미지를 높은 해상도로 만들기 위해서 고해상도 보정을 사용할 수 있다.

 - `고해상도 보정 구성`
    - WebUI > 고해상도 보정
    - 업스케일러: R-ESRGAN 4x+Anime6B(2D 애니풍), SwinIR 4x(실사풍)
    - 디노이즈 강도
        - 업스케일링 하면서 기존 이미지와 얼마나 다르게 할것인지 조정
        - 0.4 정도를 디폴트 값으로 높낮이 조정
        - 0.4 ~ 0.5 추천. 0.5 이상은 기존 이미지가 많이 달라진다.
    - 업스케일 배율
        - 몇 배 사이즈로 진행할 것인지 조정
        - 기본값 2
 - `고해상도 보정 실제 사용법`
    - 체크를 활성화하고 이미지를 생성해도 되지만, 고해상도 이미지 제작이 오래걸리기 떄문에 효율적이지 않다.
    - 기본적으로 체크 해제 후 제작을 하다가 마음에 드는 이미지가 나왔을 때, 시드를 고정하고 고해상도 보정을 켜고 다시 이미지를 생성하는 식으로 진행한다.

### 2-6. 2D 애니메이션 초상화/상반신 일러스트 만들기 (실습)

 - 모델
    - https://civitai.com/models/30240/toonyou
    - https://civitai.com/models/7240/meinamix
    - https://civitai.com/models/44219/camelliamix25d
 - `근접 얼굴 초상화`
    - 샘플링 단계: 30
    - 업스케일링 과정
        - 시드 고정
        - 고해상도 보정 활성화
        - 업스케일러: R-ESRGAN 4x+ Anime6B
        - 디노이즈 강도: 0.45
        - 업스케일 배율: 2
```
# 여자
# Positive
(best quality:1.3), (1girl:1.4), (close_up:1.3), (intricate_details:1.2), red_hair, ponytail, smile, pink_lips, black_ribbon, aurora, (cute:1.2), (brown_eyes), sky, cloud

# Negative
(low quality:1.3), (blur:1.1), nsfw

## 남자
# Positive
(best quality:1.3), (1boy:1.4), (close_up:1.3), (intricate_datails:1.1), suit, (gray_short_hair), (beard stubble:1.2), (square_glasses:1.2),

# Negative
(low quality:1.3), (blur:1.1), nsfw, (finger:1.1)
```

 - `상반신 인물 일러스트`
```
# Positive
(best quality:1.3), (frog:1.4), (upper body:1.3), (intricate_datails:1.1), (anthropomorphize:1.3), (robe:1.2), light, (orb:1.2), magic, (sage:1.2), castle, (cinematic:1.2), (solo:1.2)

# Negative
(low quality:1.3), (blur:1.1), nsfw, (finger:1.1)
```

### 2-7. 2D 애니메이션 인물 전신, 배경 일러스트 만들기 (실습)

전신의 특징은 다양한 자세를 표현하고 배경과 잘 어울리게 생성하는 것이다. 배경의 특징은 얼마나 분위기를 잘 표현하는지이다.

 - `모델`
   - https://civitai.com/models/7240/meinamix
   - https://civitai.com/models/44219/camelliamix25d
   - 배경: https://civitai.com/models/30363/cheesed-out-anime-backgrounds
 - `인물 전신`
    - 샘플링 단계: 30
    - 업스케일링 과정
        - 시드 고정
        - 고해상도 보정 활성화
        - 업스케일러: R-ESRGAN 4x+ Anime6B
        - 디노이즈 강도: 0.45
        - 업스케일 배율: 2
        - A 디테일러 활성화
```
## 여성 전신
# Positive
(best quality:1.3), (1girl:1.4), (full_body:1.3), (dancing:1.3), dress, (wind:1.1), long_hair, dreamy, light, smile, forest, fleid, (cinematic:1.3)

# Negative
(low quality:1.3), (blurry:1.2), nsfw

## 남성 전신
# Positive
(best quality:1.3), (1man:1.4), (full_body:1.3), (dragon:1.4), magic, magician, fire, (bald_head:1.2), (staff:1.1), dark, animal, outdoors

# Negative
(low quality:1.3), blur, nsfw
```

 - `배경 일러스트`
```
## 초원/폭포 배경
# Positive
(best quality:1.3), (sky:1.2), cloud, forest, waterfall, (nature:1.1), cg, (wallpaper:1.2), wind, (landscape:1.2)

# Negative
(low quality:1.3), blur, nsfw

## 달빛이 비추는 빗길 배경
# Positive
(best quality:1.3), (city:1.3), night, moon, start, neon_glow, (Depth of field:1.2), (cinematic), (wallpaper:1.2), (street:1.1), (rain:1.4)

# Negative
(low quality:1.3), blur, nsfw
```

### 2-8. 실사풍 초상화/상반신 일러스트 만들기 (실습)

 - `실사풍 참고사항`
   - 모델에 대해서 실사로 학습한 모델을 이용하고, VAE도 실사풍에 맞는 걸로 변경하는 것이 좋다.
   - 모델: https://civitai.com/models/43331/majicmix-realistic
   - VAE: https://huggingface.co/stabilityai/sd-vae-ft-mse-original/blob/main/vae-ft-mse-840000-ema-pruned.ckpt
```
## 실사풍 여성 초상화
# Positive
(realistic:1.3), (best quality:1.3), (1girl:1.4), (close_up:1.1), (space:1.2), (star), (beautiful_blue_eyes:1.3), outfocusing, raw_photo, (film_grain:1.2), (space_background:1.3)

# Negative
(low quality:1.3), blur, nsfw

## 실사풍 남성 상반신
# Positive
(realistic:1.3), (best quality:1.3), (1boy:1.4), (upper_body:1.3), (boxer:1.2), red_gloves, (gym:1.1), (punching:1.4), (dynamic pose:1.2)

# Negative
(low quality:1.3), blur, nsfw
```

### 2-9. 실사풍 전신/배경 일러스트 만들기 (실습)

```
## 실사풍 전신
# Positive
(realistic:1.3), (best quality:1.3), (girl:1.4), (full_body:1.3), (surfing:1.3), (waves:1.2), smile, sunlight, summer, ocean, (red_rash_guard:1.1), (red:1.8), windy, shine, sunshine, (intricate_detail:1.3)

# Negative
(low quality:1.3), blur, nsfw

## 실사풍 배경
# Positive
(realistic:1.3), (best quality:1.3), (no_humans:1.5), (snow:1.2), (street:1.3), footprints, light, sunshine, (wallpaper:1.2), (hyper_realistic:1.2), (snowman:1.1)

# Negative
(low quality:1.3), blur, nsfw, (humans:1.4)
```

## 3. LoRA 개념 및 활용법

Stable Diffusion에서 LoRA는 Low-Rank Adaptation의 줄임말로, 기존의 모델을 전체적으로 재학습하지 않고도 새로운 스타일이나 특정 개념을 학습시키기 위한 경량화된 학습 방식입니다.

Stable Diffusion 같은 대형 모델은 수백만~수십억 개의 파라미터를 가지고 있어서, 특정 스타일(예: 어떤 화가의 화풍)이나 인물(예: 특정 유명인 얼굴)을 학습시키려면 많은 자원과 시간이 든다. 

LoRA는 기존 모델을 거의 건드리지 않으면서, 일부 중요한 부분에만 학습한 가능한 작은 어댑터(모듈)를 끼워 넣는 방식이다.

 - 체크포인트 모델은 보통 범용성 있는 형태로 구성되어있다. 특정 스타일을 모아둔 모델도 있지만, 그런 모델조차 넓은 범위를 커버할 수 있을 만큼 많은 이미지를 학습한 형태이다.
 - 때문에 특정 상황, 자세, 오브젝트, 스타일을 프롬프트만으로 표현하는 것에 한계가 존재한다. 이러한 한계를 꺠기 위해 조금 더 작은 범위이면서 특정 범위인 이미지만 학습한 형태가 로라이다.
 - 로라는 체크포인트 위에 덮어서 특정 부분에 대한 처리만 진행하게 된다.
 - 로라의 특징은 체크포인트 위에서 사용된다는 것과 다른 로라와 중복으로 사용할 수 있고 우선순위도 조절할 수 있다.
 - 예시
   - Stable Diffusion 모델 + LoRA("고흐 스타일") → 고흐 화풍 이미지 생성 가능
   - Stable Diffusion 모델 + LoRA("수목화 스타일") → 수목화 스타일 화풍 이미지 생성 가능

### 3-1. LoRA 사용 방법

 - `LoRA 다운로드`
   - HuggingFace나 Civitai에서 LoRA 파일 다운로드
   - .safetensors 또는 .pt 확장자의 LoRA 파일을 다운로드
   - 모델과 LoRA 버전이 호환이 되어야 한다.
   - Usage Tips 항목에 사용 가중치와 Trigger Words(트리거되는 단어)를 참고한다.
 - `WebUI에 옮기기`
   - stable-diffusion-webui/models/Lora/ 폴더에 다운로드한 파일 이동
 - `WebUI`
   - /models/Lora/ 하위에 LoRA 파일이 존재한다면 WebUI의 LoRA 탭에 노출된다.
   - 사용하고자 하는 LoRA를 클릭하면 프롬프트 내용에 추가가 된다. 가중치는 0 ~ 1 범위로 조정하여 사용한다.
   - 즉, 특정 LoRA 적용은 프롬프트에 특정 LoRA 유발 키워드가 사용되는 것이다.
 - `주의사항`
   - LoRA 선택시 기본적으로 1이 들어간다. 상세페이지에서 추천하는 값이 있는데, 보통은 그것보다 더 낮은 값으로 시작해서 서서히 올리는 것이 추천된다.
   - LoRA는 모델과의 연결성이 중요하다. 실사 모델에서 혹은 2D 애니메이션 모델에서만 워킹하는 경우도 많으며 같은 실사여도 그 풍에 따라서 안맞는 경우도 많이 생길 수 있다.
   - LoRA는 LoRA간의 연결성도 영향을 크게 받는다. 서로 충돌될 수 밖에 없는 로라를 같이 사용하면 기괴한 이미지가 나오기 좋고, 자연스럽게 섞이는 경우보다는 충돌이 나는 경우가 더 많기 때문에 2개 이상의 로라를 사용할 경우 가중치를 적절하게 조절해야 한다.
 - `같이 쓰기 좋은 익스텐션`
   - Stable Diffusion Webui Civitai Helper

### 3-2. LoRA 실습

 - `모델`
   - 아케인 스타일 LoRA: https://civitai.com/models/7094?modelVersionId=8339
   - 특정 인물 LoRA: https://civitai.com/models/8416/gakki-or-aragaki-yui-or
   - 특정 인물 LoRA: https://civitai.com/models/130896/ai-shinozaki
   - VAE: https://huggingface.co/stabilityai/sd-vae-ft-mse-original/blob/main/vae-ft-mse-840000-ema-pruned.ckpt

```
## 아케인 LoRA 사용
# Positive
(best quality:1.3), (1girl:1.3), (upper body:1.3), (blonde_hair:1.2), <lora:arcane_offset:0.7>, <lora:lihui4JXK-b2-bf16-128-128-1-rel-ep3-768-DA-5015fix:0.5> (white background:1.3)

# Negative
(low quality:1.3), (blurry:1.2), (nsfw:0.9)

## 특정 인물 LoRA 사용
# Positive
(best quality:1.3), (1girl:1.3), (upper body:1.3), (black_long_hair:1.2), <lora:gakki:0.8>, <lora:AiShinozakiv6:0.6>, (korean:1.3), (intricate_detail:1.1), looking at viewer

# Negative
(low quality:1.3), (blurry:0.9), (nsfw:0.9)
```

## 4. Image to Image를 통하여 원하는 이미지 

I2I(Image to Image)는 기존 이미지를 기반으로 새로운 이미지를 변형해서 생성하는 방식이다.

입력하는 이미지의 퀄리티, 방향성에 따라 결과가 나온다.

 - __기본 I2I__: 이미지와 프롬프트를 같이 입력하면, 그 이미지를 기반으로 프롬프트를 적용시켜 새로운 이미지를 생성한다. 이때 이미지 전체의 사이즈 조절이 가능하다.
 - __인페인팅__: 이미지의 특정 부분만 선택하여 그 부분에만 프롬프트를 적용시켜 새로운 이미지 생성
 - __아웃페인팅__: 이미지의 바깥 부분, 즉 아직 생성되지 않은 부분으르 기존의 이미지를 참고하여 영역을 확장하여 그리게 된다.

### 4-1. I2I 기본 사용법

WebUI에서 img2img 탭으로 이동한다. 기본적으로 txt2img와 동일하게 긍정/부정 프롬프트를 입력할 수 있고, 다른 점으로는 이미지를 업로드할 수 있다.

 - `ABG 리무버 (ABG_extension)`
   - ABG 리무버는 생성한 이미지의 배경을 분리해주는 익스텐션이다.
   - 이를 활용하면 다수의 캐릭터를 생성하거나, 배경을 변경하기에 좋다.
   - 스크립트에 ABG Remover를 선택하고, 이미지를 생성하면 원본 이미지, 배경 이미지, 인물 누끼 이미지 3장이 생성된다.
 - `ABG 리무버 활용`
   - T2I로 인물 생성
   - ABG REMOVER로 인물 누끼 사진 획득
   - 포토샵에서 인물 누끼 사진에 원하는 배경 색칠
   - I2I로 인물 누끼 + 색칠 배경에 디노이즈 강도를 높혀서 배경 관련 프롬프트 적용
   - 동일한 인물에 다른 배경이 생성된다.

### 4-2. I2I 실습

 - `애니메이션 > 실사`
   - 참고 이미지: 드래곤볼 손오공
   - 이미지 크기: 512*512
   - 디노이즈 강도: 0.55
```
# Positive
(best quality:1.3), (1man:1.4), (upper body:1.3), korean, (black_hair:1.2), (muscular:1.1)


# Negative
(low quality:1.3), blurry, nsfw
```

 - `실사 배경 > 애니메이션 배경`
   - 체크포인트 모델: camelliamix
   - 이미지 크기: 1024*1024
   - 디노이즈 강도: 0.5
```
# Positive
(best quality:1.3)

# Negative
(low quality:1.3), blurry, nsfw
```

### 4-3. 인페인팅

인페인팅(Inpainting)은 이미지의 일부를 선택해서 다시 생성하거나 수정하는 기능을 말합니다. 기존 이미지에서 특정 영역을 지우고 그 부분만 AI가 자연스럽게 채워주는 기능입니다.

 - `인페인팅 사용 방법`
   - WebUI > img2img > Generation > 인페인트
      - 대상 이미지 업로드
      - 수정하고 싶은 영역을 마스킹
      - 해당 부분에 넣고 싶은 내용을 프롬프트로 작성
   - 인페인트 옵션
      - 마스크 모드: 마스킹 영역을 처리할지, 마스킹 영역 외에 영역을 처리할지
      - 인페인트 영역: 새로 생성되는 결과물이 인페인트 영역만을 기준으로 할지, 전체 영역을 포함하여 만들지 지정 (전체 영역을 담는 것이 더 자연스럽다.)
      - 디노이즈 강도: 원본 이미지에서 변화 강도. 특정 영역을 바꾸려는 목적으로 0.7 이상 주는 것이 좋다.
 - `인페인팅 정리`
   - 특정 부분만 골라서 수정할 수 있게 되면서 완벽한 이미지를 구상할 수 있을 것 같지만, 결국 어떻게 이미지를 제작해낼 지 내 머릿속에 결과가 없다면 한계가 있다.
   - T2I 처럼, 내 머리 속에 결과가 없어도 대략적인 것만으로도 AI가 유를 창조해줬다면, I2I는 더 나아가 인페인팅의 경우는 내 머릿 속에 하고 싶은 목표가 정확할 수록 더 좋은 결과를 낸다.

### 4-4. 아웃페인팅

 - `아웃페인팅`
   - 지금의 이미지가 마음에 드는 상태에서 보완을 하는 개념
   - 인페인팅과 다르게 새로운 것을 만든다. 영역 확장
 - `아웃페인팅 사용 방법`
   - WebUI > img2img > 스크립트 리스트 > 아웃페인팅 마크2
   - 아웃페인팅 옵션
      - 확장시킬 픽셀 수: 한 번에 넓게 확장할 수록 퀄리티 감소
      - 아웃페인팅 방향: 어느 방향으로 아웃페인팅할 것인지
      - 감쇠 지수: 테스트 결과 가장 높은 값이 자연스러움
      - 색 다양성: 이미지 본연의 색 베리에이션에 영향 받음

## 5. ControlNet을 활용하여 자세 및 구도 조정하기

컨트롤넷(ControlNet)은 딥러닝 기반 이미지 생성 모델, 특히 Stable Diffusion 같은 모델에서 사용자의 조건(제어 조건)을 정밀하게 반영할 수 있도록 도와주는 조건부 제어 네트워크입니다.

기존의 Stable Diffusion은 텍스트 프롬프트만으로 이미지를 생성하지만, ControlNet은 여기에 추가적으로 스케치, 윤곽선, 포즈, 깊이 정보, 에지 등을 입력으로 넣어서 더 정밀하고 제어된 이미지 생성을 가능하게 한다.

 - `컨트롤넷 설치 방법`
   - WebUI > 확장 기능 > URL에서 설치
   - https://github.com/Mikubill/sd-webui-controlnet
 - `컨트롤넷 모델 설치`
   - 컨트롤넷 모델은 굉장히 많은 기능에 따라 용량이 크다.
   - stable-diffusion-webui/models/ControlNet 경로에 모델을 이동시킨다.
   - https://civitai.com/models/9251?modelVersionId=11017
 - `컨트롤넷 사용 방법`
   - 이미지: 참고할 이미지, 자세 원본 이미지, 자세 이미지 등 포즈와 관련된 이미지를 넣는 공간
   - 활성화 체크박스: 컨트롤넷 ON/OFF 활성화를 켜야 동작
   - 픽셀 퍼펙트: 이미지의 해상도를 자동으로 계산. 켜두고 사용
   - 사전 처리기: 어떤 컨트롤넷 기능을 사용할지 선택
   - 모델: 어떤 컨트롤넷 모델을 사용할지 선택 (다운받은 모델 선택)
 - `상황에 따른 사전 처리기 사용 방법`
   - 이미지에서 포즈의 뼈대를 추출할 때
      - 사전 처리기: openpose
      - 컨트롤넷 입력 이미지에 뼈대를 추출할 원본 이미지를 넣고, 사용
   - 포즈의 뼈대로 이미지를 만들 때
      - 사전 처리기: none
      - 컨트롤넷 입력 이미지에 포즈 뼈대를 넣고, 프롬프트 동작


## 6. 1인 프로젝트와 Stable Diffusion 활용 사례

 - __게임, 웹툰의 2D 일러스트 초안 작업__
   - 규모가 있는 회사에서는 일반적인 AI 이미지 생성을 진행하기보단 내부 아티스트의 작품을 기반으로 Lora를 직접 생성해서 사용하는 방식을 주로 사용
   - 이미지 한 컷을 만드는 건 쉽지만, 통일성을 유지한채로 여러 컷에 등장하거나, 모델링, 애니메이션을 유지하는 것은 현재로는 사람의 작업이 많이 필요
 - __커머셜 아트웍에서의 실사 보정으로 활용__
   - 상품 상세 페이지 보정으로 굉장히 많이 사용
   - 이미지를 직접 바로 프롬프트로 생성하기 보다는 제품을 포함한 사진 촬영을 한 뒤에 모델을 교체하고 배경을 교체하는 방식으로 활용
 - __브랜드 디자인을 위한 가상 컨셉 이미지 제작__
   - AI에서는 비현실적인 표현을 자유롭게 진행할 수 있기 때문에, 기존에 존재하는 제품이나 인물이 아닌 형태의 구성의 표현이 가능
   - 현실에 존재하지 않는 제품을 이미지로 생성하여 표현하는 것도 좋지만, 아직까지는 섬세한 조정이 잘 되진 않아 적당한 리터칭을 포함하고 배경과 촬영 현장 자체를 제어하는 형태로 작업 진행

## 7. 실습

### 7-1. 커머셜 상세 페이지 가상 모델 활용하여 만들어보기

 - `준비 사항`
   - 기본 사진이 필요
   - https://civitai.com/models/43331/majicmix-realistic
   - https://civitai.com/models/8416/gakki-or-aragaki-yui-or
   - https://civitai.com/models/130896/ai-shinozaki
```
1. img2img로 얼굴 변경
 - 원본 이미지 입력
 - 얼굴 부분 인페인팅
   - 남성 -> 여성으로 변경하기 위해 얼굴 부분을 넘어서 머리카락 범위까지 인페인팅
   - 연속성을 위해서 Lora를 사용

Positive
(best quality:1.3), (1girl:1.4), (realistic:1.3), (korean:1.3), raw photo, lens flare, (photorealistic:1.2), (flim grain:1.2), (long hair:1.3), <lora:gakki:0.65>, gakki, <lora:AiShinozakiv6:0.35>

Negative
(low quality:1.3), (blurry:1.1), (nsfw:0.9)


2. img2img로 몸 변경
 - 인페인팅 범위를 몸으로 설정

Positive
(best quality:1.3), (1girl:1.4), (realistic:1.3), (korean:1.3), raw photo, lens flare, (photorealistic:1.2), (flim grain:1.2), (long hair:1.3), (large breasts:1.2), (t-shirt:1.4)

Negative
(low quality:1.3), (blurry:1.1), (nsfw:0.9)
```

### 7-2. 브랜드 디자인을 위한 가상 컨셉 작품 만들어보기

 - 브랜드의 미래 가치를 증가시키며, 호기심을 증폭시키는 방법으로 존재하지 않는 제품에 대한 컨셉 디자인을 공개
 - 가상의 상품이라고 하더라도, 보통은 완전히 처음부터 이미지를 생성하기보단 기존의 제품, 전작의 촬영을 기반으로 AI 이미지 생성을 활용하는 편이 더 좋은 결과물을 낼 수 있다.
 - `준비 사항`
   - https://civitai.com/models/43331/majicmix-realistic
   - https://civitai.com/models/85514/cosmetics
   - https://civitai.com/models/263111/moomoo-product-protography
   - https://civitai.com/models/452399/spaceengineers-conceptart

```
1. txt2img

Positive
(best quality:1.3), (perfume:1.2), (realistic:1.3), (cosmetics:1.2), <lora:E commerce Photography_20231010181646:0.6>, <lora:product_design_v3:0.6>, (fire:1.4)

Negative
low quality, blurry, nsfw

2. img2img로 부족한 부분 변경

```


